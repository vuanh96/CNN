{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydoclist = ['Julie loves me more than Linda loves me',\n",
    "'Jane likes me more than Julie loves me',\n",
    "'He likes basketball more than baseball']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jane likes me more than Julie loves me'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = mydoclist[1]\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jane', 'likes', 'me', 'more', 'than', 'Julie', 'loves', 'me']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = doc.split()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.count('likes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'He': 1,\n",
       "         'likes': 1,\n",
       "         'basketball': 1,\n",
       "         'more': 1,\n",
       "         'than': 1,\n",
       "         'baseball': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for doc in mydoclist:\n",
    "    tf = Counter()\n",
    "    for word in doc.split():\n",
    "        tf[word] += 1\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['He', 'likes', 'basketball', 'more', 'than', 'baseball'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Name', 'Age', 'Class'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {'Name': 'Zara', 'Age': 7, 'Class': 'First'}\n",
    "dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Zara', 7, 'First'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Name', 'Zara'), ('Age', 7), ('Class', 'First')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return lexicon\n",
    "\n",
    "def tf(term, document):\n",
    "    return freq(term, document)\n",
    "\n",
    "def freq(term, document):\n",
    "    return document.split().count(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'He',\n",
       " 'Jane',\n",
       " 'Julie',\n",
       " 'Linda',\n",
       " 'baseball',\n",
       " 'basketball',\n",
       " 'likes',\n",
       " 'loves',\n",
       " 'me',\n",
       " 'more',\n",
       " 'than'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = build_lexicon(mydoclist)\n",
    "vocabulary #set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseball, Julie, me, Linda, likes, Jane, more, basketball, loves, than, He\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['baseball',\n",
       " 'Julie',\n",
       " 'me',\n",
       " 'Linda',\n",
       " 'likes',\n",
       " 'Jane',\n",
       " 'more',\n",
       " 'basketball',\n",
       " 'loves',\n",
       " 'than',\n",
       " 'He']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = list(vocabulary)\n",
    "print(', '.join(b))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [baseball, Julie, me, Linda, likes, Jane, more, basketball, loves, than, He]\n"
     ]
    }
   ],
   "source": [
    "print('Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [baseball, Julie, me, Linda, likes, Jane, more, basketball, loves, than, He]\n",
      "The doc is \"Julie loves me more than Linda loves me\"\n",
      "The tf vector for Document 1 is [0, 1, 2, 1, 0, 0, 1, 0, 2, 1, 0]\n",
      "The doc is \"Jane likes me more than Julie loves me\"\n",
      "The tf vector for Document 2 is [0, 1, 2, 0, 1, 1, 1, 0, 1, 1, 0]\n",
      "The doc is \"He likes basketball more than baseball\"\n",
      "The tf vector for Document 3 is [1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1]\n",
      "All combined, here is our master document term matrix: \n",
      "[[0, 1, 2, 1, 0, 0, 1, 0, 2, 1, 0], [0, 1, 2, 0, 1, 1, 1, 0, 1, 1, 0], [1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "doc_term_matrix = []\n",
    "print('Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n",
    "for index, doc in enumerate(mydoclist):\n",
    "    print('The doc is \"' + doc + '\"')\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary]\n",
    "    tf_vector_string = ', '.join(format(freq) for freq in tf_vector)\n",
    "    print('The tf vector for Document %d is [%s]' % (index+1, tf_vector_string))\n",
    "    doc_term_matrix.append(tf_vector)\n",
    "    \n",
    "print('All combined, here is our master document term matrix: ')\n",
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing vectors to L2 Norm = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A regular old documnet term matrix: \n",
      "[[0 1 2 1 0 0 1 0 2 1 0]\n",
      " [0 1 2 0 1 1 1 0 1 1 0]\n",
      " [1 0 0 0 1 0 1 1 0 1 1]]\n",
      "\n",
      "A document term matrix with row-wise L2 norms of 1:\n",
      "[[ 0.          0.28867513  0.57735027  0.28867513  0.          0.\n",
      "   0.28867513  0.          0.57735027  0.28867513  0.        ]\n",
      " [ 0.          0.31622777  0.63245553  0.          0.31622777  0.31622777\n",
      "   0.31622777  0.          0.31622777  0.31622777  0.        ]\n",
      " [ 0.40824829  0.          0.          0.          0.40824829  0.\n",
      "   0.40824829  0.40824829  0.          0.40824829  0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def l2_normalizer(vector):\n",
    "    denom = np.sum([element**2 for element in vector])\n",
    "    return [(element / math.sqrt(denom)) for element in vector]\n",
    "\n",
    "doc_term_matrix_l2 = []\n",
    "for vec in doc_term_matrix:\n",
    "    doc_term_matrix_l2.append(l2_normalizer(vec))\n",
    "    \n",
    "print ('A regular old documnet term matrix: ')\n",
    "print (np.matrix(doc_term_matrix))\n",
    "print ('\\nA document term matrix with row-wise L2 norms of 1:')\n",
    "print (np.matrix(doc_term_matrix_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 1, 0, 0, 1, 0, 2, 1, 0], [0, 1, 2, 0, 1, 1, 1, 0, 1, 1, 0], [1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.46410161514\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from numpy import linalg as la\n",
    "print(la.norm(doc_term_matrix[0]))\n",
    "print(la.norm(doc_term_matrix_l2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF frequency weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numDocsContaining(word, doclist):\n",
    "    doccount = 0\n",
    "    for doc in doclist:\n",
    "        if freq(word, doc) > 0:\n",
    "            doccount += 1\n",
    "    return doccount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word, doclist):\n",
    "    num_docs = len(doclist)\n",
    "    df = numDocsContaining(word, doclist)\n",
    "    return np.log(num_docs/df + 1)\n",
    "\n",
    "my_idf_vector = [idf(word, mydoclist) for word in vocabulary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [baseball, Julie, me, Linda, likes, Jane, more, basketball, loves, than, He]\n",
      "The inverse documnet frequency vector is [1.386294, 0.916291, 0.916291, 1.386294, 0.916291, 1.386294, 0.693147, 1.386294, 0.916291, 0.693147, 1.386294]\n"
     ]
    }
   ],
   "source": [
    "print ('Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n",
    "print ('The inverse documnet frequency vector is [' + ', '.join(format(idf, 'f') for idf in my_idf_vector) + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.38629436  0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.91629073  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.91629073  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          1.38629436  0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.91629073  0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          1.38629436\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.69314718  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   1.38629436  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.91629073  0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.69314718  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          1.38629436]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_idf_matrix(idf_vector):\n",
    "    idf_mat = np.zeros((len(idf_vector), len(idf_vector)))\n",
    "    np.fill_diagonal(idf_mat, idf_vector)\n",
    "    return idf_mat\n",
    "\n",
    "my_idf_matrix = build_idf_matrix(my_idf_vector)\n",
    "print (my_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 1, 0, 0, 1, 0, 2, 1, 0],\n",
       " [0, 1, 2, 0, 1, 1, 1, 0, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix_tfidf = []\n",
    "\n",
    "#performing tf-idf matrix multiplication\n",
    "for tf_vector in doc_term_matrix:\n",
    "    doc_term_matrix_tfidf.append(np.dot(tf_vector, my_idf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing\n",
    "doc_term_matrix_tfidf_l2 = []\n",
    "for tf_vector in doc_term_matrix_tfidf:\n",
    "    doc_term_matrix_tfidf_l2.append(l2_normalizer(tf_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseball', 'Julie', 'me', 'Linda', 'likes', 'Jane', 'more', 'basketball', 'loves', 'than', 'He'}\n",
      "[[ 0.          0.28359822  0.56719644  0.42906755  0.          0.\n",
      "   0.21453377  0.          0.56719644  0.21453377  0.        ]\n",
      " [ 0.          0.30958879  0.61917759  0.          0.30958879  0.46838976\n",
      "   0.23419488  0.          0.30958879  0.23419488  0.        ]\n",
      " [ 0.50399273  0.          0.          0.          0.33312107  0.\n",
      "   0.25199636  0.50399273  0.          0.25199636  0.50399273]]\n"
     ]
    }
   ],
   "source": [
    "print (vocabulary)\n",
    "print (np.matrix(doc_term_matrix_tfidf_l2)) # np.matrix() just to make it easier to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'julie': 4, 'loves': 7, 'me': 8, 'more': 9, 'than': 10, 'linda': 6, 'jane': 3, 'likes': 5, 'he': 2, 'basketball': 1, 'baseball': 0}\n",
      "[[0 0 0 0 1 0 1 2 2 1 1]\n",
      " [0 0 0 1 1 1 0 1 2 1 1]\n",
      " [1 1 1 0 0 1 0 0 0 1 1]]\n",
      "[[ 0.          0.          0.          0.          0.28945906  0.\n",
      "   0.38060387  0.57891811  0.57891811  0.22479078  0.22479078]\n",
      " [ 0.          0.          0.          0.41715759  0.3172591   0.3172591\n",
      "   0.          0.3172591   0.6345182   0.24637999  0.24637999]\n",
      " [ 0.48359121  0.48359121  0.48359121  0.          0.          0.36778358\n",
      "   0.          0.          0.          0.28561676  0.28561676]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(min_df=1)\n",
    "term_freq_matrix = count_vectorizer.fit_transform(mydoclist)\n",
    "print (\"Vocabulary:\", count_vectorizer.vocabulary_)\n",
    "print (term_freq_matrix.todense())\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(norm=\"l2\")\n",
    "tf_idf_matrix = tfidf.fit_transform(term_freq_matrix)\n",
    "print (tf_idf_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.28945906  0.\n",
      "   0.38060387  0.57891811  0.57891811  0.22479078  0.22479078]\n",
      " [ 0.          0.          0.          0.41715759  0.3172591   0.3172591\n",
      "   0.          0.3172591   0.6345182   0.24637999  0.24637999]\n",
      " [ 0.48359121  0.48359121  0.48359121  0.          0.          0.36778358\n",
      "   0.          0.          0.          0.28561676  0.28561676]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(mydoclist)\n",
    "\n",
    "print (tfidf_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
